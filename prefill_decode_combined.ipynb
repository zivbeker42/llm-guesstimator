{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "REPO_URL = \"https://github.com/openai/llm-guesstimator.git\"\n",
    "\n",
    "bash_setup = f\"\"\"\n",
    "setup_llm_guesstimator() {{\n",
    "  if [[ -n \\\"${{COLAB_RELEASE_TAG:-}}\\\" ]]; then\n",
    "    local repo_path=\\\"/content/llm-guesstimator\\\"\n",
    "    if [[ ! -d \\\"$repo_path\\\" ]]; then\n",
    "      git clone \\\"{REPO_URL}\\\" \\\"$repo_path\\\"\n",
    "    fi\n",
    "  fi\n",
    "}}\n",
    "setup_llm_guesstimator\n",
    "\"\"\"\n",
    "\n",
    "subprocess.run([\"bash\", \"-lc\", bash_setup])\n",
    "\n",
    "repo_path = \"/content/llm-guesstimator\" if \"google.colab\" in sys.modules else os.path.abspath('.')\n",
    "\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "os.chdir(repo_path)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a51e235a",
   "metadata": {
    "id": "a51e235a"
   },
   "source": [
    "# LLM Prefill & Decode: Compute vs Memory Boundness \u2014 Corrected Formulas, Intuition, and Plots\n",
    "\n",
    "This notebook consolidates the corrected equations for **prefill** (encode) and **decode** (per new token) phases of Transformer-based LLM inference, derives **arithmetic intensity vs machine balance** sanity checks, and visualizes **compute time**, **memory time**, and **max(time)** across relevant ranges of sequence length $L$ and batch size $S$.\n",
    "\n",
    "We follow the convention that **every matmul costs $2mnp$ FLOPs** (multiply + add)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5f108",
   "metadata": {
    "id": "1da5f108"
   },
   "source": [
    "## Parameters (Default Values)\n",
    "\n",
    "- $S$: concurrent requests at the step (batch size)\n",
    "- $L$: context length (prefill) / past tokens (decode)\n",
    "- $P = S \\cdot L$: \"token budget\"\n",
    "- $d$: hidden size\n",
    "- $r$: FFN expansion ratio ($\\approx 4$)\n",
    "- $n_\\ell$: number of Transformer layers\n",
    "- $\\text{dtype}_B$: bytes per element (e.g., 2 for FP16/BF16)\n",
    "- $\\mathcal{F}$: sustained GPU FLOPs/s (e.g., A100-40GB FP16 TC $\\approx 3.12\\times 10^{14}$)\n",
    "- $BW$: device memory bandwidth in B/s (e.g., A100-40GB $\\approx 1.555\\times 10^{12}$)\n",
    "- $c_{\\text{act}}$: activation I/O multiplier (use 12)\n",
    "\n",
    "We also define the **machine balance** $\\beta = \\mathcal{F} / BW$ (FLOPs per byte)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e8370",
   "metadata": {
    "id": "de6e8370"
   },
   "source": [
    "## Corrected Formulas\n",
    "\n",
    "### Prefill (encode) \u2014 per step\n",
    "**Compute FLOPs (per layer, across $S$ requests):**\n",
    "\n",
    "$$(8+4r) L d^2 + 4 L^2 d$$\n",
    "\n",
    "**Compute time:**\n",
    "\n",
    "$$T_{\\text{prefill}}^{\\text{compute}}(S,L) = \\frac{n_\\ell S \\big((8+4r) L d^2 + 4 L^2 d\\big)}{\\mathcal{F}}$$\n",
    "\n",
    "**Memory bytes:**\n",
    "\n",
    "$$\\text{Bytes}_{\\text{prefill}} = n_\\ell \\Big((4+2r) d^2 + (2+c_{\\text{act}}) S L d \\Big) \\, \\text{dtype}_B$$\n",
    "\n",
    "**Memory time:**\n",
    "\n",
    "$$T_{\\text{prefill}}^{\\text{memory}}(S,L) = \\frac{n_\\ell \\Big((4+2r) d^2 + (2+c_{\\text{act}}) S L d \\Big) \\, \\text{dtype}_B}{BW}$$\n",
    "\n",
    "---\n",
    "\n",
    "### Decode (per new token) \u2014 per step\n",
    "**Compute FLOPs (per layer, across $S$ requests):**\n",
    "\n",
    "$$(8+4r) d^2 + 4 L d$$\n",
    "\n",
    "**Compute time per token:**\n",
    "\n",
    "$$T_{\\text{token}}^{\\text{compute}}(S,L) = \\frac{n_\\ell S \\big((8+4r) d^2 + 4 L d\\big)}{\\mathcal{F}}$$\n",
    "\n",
    "**Memory bytes (per token, across all $S$ and layers):**\n",
    "\n",
    "$$\\text{Bytes}_{\\text{token}} = n_\\ell \\Big((4+2r) d^2 + (2SL + (2+c_{\\text{act}})S) d \\Big) \\, \\text{dtype}_B$$\n",
    "\n",
    "**Memory time per token:**\n",
    "\n",
    "$$T_{\\text{token}}^{\\text{memory}}(S,L) = \\frac{n_\\ell \\Big((4+2r) d^2 + (2SL + (2+c_{\\text{act}})S) d \\Big) \\, \\text{dtype}_B}{BW}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753af614",
   "metadata": {
    "id": "753af614"
   },
   "source": [
    "## Intuition & Insights\n",
    "\n",
    "- **Prefill** grows $O(L^2)$ due to attention; tends compute-bound for large $L$.\n",
    "- **Decode** grows linearly in $L$; KV-cache reads dominate memory, so decode tends memory-bound beyond short contexts.\n",
    "- $S$ scales both compute and memory similarly, so $L$ mainly drives boundness.\n",
    "- **Arithmetic Intensity (AI)** $= \\text{FLOPs}/\\text{Bytes}$: if $AI > \\beta$ \u2192 compute-bound; else memory-bound.\n",
    "- For A100-40GB, $\\beta \\approx 200$ FLOPs/byte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cbb916",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0cbb916",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759266142209,
     "user_tz": -180,
     "elapsed": 25,
     "user": {
      "displayName": "ziv beker",
      "userId": "07904590467861271362"
     }
    },
    "outputId": "9b827deb-ea10-470a-8d00-2c767b74ae88"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.config import GRID_SETTINGS, get_hardware_config, get_model_config\n",
    "from utils.math_utils import (\n",
    "    decode_compute_time,\n",
    "    decode_memory_time,\n",
    "    prefill_compute_time,\n",
    "    prefill_memory_time,\n",
    ")\n",
    "\n",
    "hardware = get_hardware_config()\n",
    "prefill_settings = GRID_SETTINGS[\"prefill\"]\n",
    "decode_settings = GRID_SETTINGS[\"decode\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ae1c3",
   "metadata": {
    "id": "493ae1c3"
   },
   "source": [
    "## Prefill Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d847f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "d5d847f8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759266147696,
     "user_tz": -180,
     "elapsed": 776,
     "user": {
      "displayName": "ziv beker",
      "userId": "07904590467861271362"
     }
    },
    "outputId": "9cbe1419-6c21-4980-d48f-a44ab5725fe7"
   },
   "outputs": [],
   "source": [
    "cfg = get_model_config(\"70B\")\n",
    "d, n_layers, r = cfg.hidden_size, cfg.num_layers, cfg.expansion_ratio\n",
    "L = np.arange(prefill_settings[\"surface_context_range\"][0], prefill_settings[\"surface_context_range\"][1] + prefill_settings[\"surface_context_range\"][2], prefill_settings[\"surface_context_range\"][2])\n",
    "for S in [1, 16]:\n",
    "    Tc = prefill_compute_time(S, L, cfg, hardware)\n",
    "    Tm = prefill_memory_time(S, L, cfg, hardware)\n",
    "    plt.plot(L, Tc, label='T_compute')\n",
    "    plt.plot(L, Tm, label='T_memory')\n",
    "    plt.plot(L, np.maximum(Tc, Tm), label='max')\n",
    "    plt.title(f'Prefill Times S={S}')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed253977",
   "metadata": {
    "id": "ed253977"
   },
   "source": [
    "## Decode Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bec4b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "79bec4b0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759266158728,
     "user_tz": -180,
     "elapsed": 495,
     "user": {
      "displayName": "ziv beker",
      "userId": "07904590467861271362"
     }
    },
    "outputId": "a38bdecc-3f9e-4d55-bbb4-c9c060c7b3ec"
   },
   "outputs": [],
   "source": [
    "cfg = get_model_config(\"70B\")\n",
    "L = np.arange(decode_settings[\"surface_past_length_range\"][0], decode_settings[\"surface_past_length_range\"][1] + decode_settings[\"surface_past_length_range\"][2], decode_settings[\"surface_past_length_range\"][2])\n",
    "for S in [1, 32]:\n",
    "    Tc = decode_compute_time(S, L, cfg, hardware)\n",
    "    Tm = decode_memory_time(S, L, cfg, hardware)\n",
    "    plt.plot(L, Tc, label='T_compute')\n",
    "    plt.plot(L, Tm, label='T_memory')\n",
    "    plt.plot(L, np.maximum(Tc, Tm), label='max')\n",
    "    plt.title(f'Decode Times S={S}')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "from utils.config import prefill_surface_grids, decode_surface_grids\n",
    "from utils.math_utils import safe_ratio\n",
    "\n",
    "cfg = get_model_config(\"70B\")\n",
    "\n",
    "prefill_S_vals, prefill_L_range = prefill_surface_grids()\n",
    "prefill_S_vals = np.array(prefill_S_vals, dtype=float)\n",
    "prefill_L_vals = np.arange(\n",
    "    prefill_L_range[0],\n",
    "    prefill_L_range[1] + prefill_L_range[2],\n",
    "    prefill_L_range[2],\n",
    "    dtype=float,\n",
    ")\n",
    "\n",
    "prefill_Sg = prefill_S_vals[None, :]\n",
    "prefill_Lg = prefill_L_vals[:, None]\n",
    "\n",
    "prefill_T_compute = prefill_compute_time(prefill_Sg, prefill_Lg, cfg, hardware)\n",
    "prefill_T_memory = prefill_memory_time(prefill_Sg, prefill_Lg, cfg, hardware)\n",
    "prefill_T_ratio = safe_ratio(prefill_T_compute, prefill_T_memory)\n",
    "\n",
    "prefill_eps = 0.05\n",
    "prefill_den = np.maximum(prefill_T_compute, prefill_T_memory)\n",
    "prefill_boundary = np.abs(prefill_T_compute - prefill_T_memory) / np.where(prefill_den == 0, 1, prefill_den) <= prefill_eps\n",
    "pi, pj = np.where(prefill_boundary)\n",
    "prefill_boundary_L = prefill_L_vals[pi]\n",
    "prefill_boundary_S = prefill_S_vals[pj]\n",
    "prefill_boundary_Z = prefill_T_compute[pi, pj]\n",
    "\n",
    "def make_surface(x_vals, y_vals, z, boundary_S, boundary_L, boundary_Z, title, zlabel):\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Surface(x=x_vals, y=y_vals, z=z, showscale=True),\n",
    "            go.Scatter3d(\n",
    "                x=boundary_S,\n",
    "                y=boundary_L,\n",
    "                z=boundary_Z,\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=3, opacity=0.8),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "            xaxis_title=\"S (batch size)\",\n",
    "            yaxis_title=\"L (tokens)\",\n",
    "            zaxis_title=zlabel,\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, t=40, b=0),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "make_surface(\n",
    "    prefill_S_vals,\n",
    "    prefill_L_vals,\n",
    "    prefill_T_compute,\n",
    "    prefill_boundary_S,\n",
    "    prefill_boundary_L,\n",
    "    prefill_boundary_Z,\n",
    "    \"Prefill \u2014 T_compute(S,L)\",\n",
    "    \"Time per prefill step (s)\",\n",
    ")\n",
    "\n",
    "make_surface(\n",
    "    prefill_S_vals,\n",
    "    prefill_L_vals,\n",
    "    prefill_T_memory,\n",
    "    prefill_boundary_S,\n",
    "    prefill_boundary_L,\n",
    "    prefill_boundary_Z,\n",
    "    \"Prefill \u2014 T_memory(S,L)\",\n",
    "    \"Time per prefill step (s)\",\n",
    ")\n",
    "\n",
    "make_surface(\n",
    "    prefill_S_vals,\n",
    "    prefill_L_vals,\n",
    "    prefill_T_ratio,\n",
    "    prefill_boundary_S,\n",
    "    prefill_boundary_L,\n",
    "    prefill_boundary_Z,\n",
    "    \"Prefill \u2014 T_compute/T_memory(S,L)\",\n",
    "    \"Ratio\",\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tvGGaxM8bzWY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759266972873,
     "user_tz": -180,
     "elapsed": 81,
     "user": {
      "displayName": "ziv beker",
      "userId": "07904590467861271362"
     }
    },
    "outputId": "591fc6de-138e-4f04-a5d3-a3835f829107"
   },
   "id": "tvGGaxM8bzWY",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "cfg = get_model_config(\"70B\")\n",
    "decode_S_range, decode_L_range = decode_surface_grids()\n",
    "decode_S_vals = np.arange(decode_S_range[0], decode_S_range[1], decode_S_range[2], dtype=float)\n",
    "decode_L_vals = np.arange(\n",
    "    decode_L_range[0],\n",
    "    decode_L_range[1] + decode_L_range[2],\n",
    "    decode_L_range[2],\n",
    "    dtype=float,\n",
    ")\n",
    "\n",
    "decode_Sg = decode_S_vals[None, :]\n",
    "decode_Lg = decode_L_vals[:, None]\n",
    "\n",
    "decode_T_compute = decode_compute_time(decode_Sg, decode_Lg, cfg, hardware)\n",
    "decode_T_memory = decode_memory_time(decode_Sg, decode_Lg, cfg, hardware)\n",
    "decode_T_max = np.maximum(decode_T_compute, decode_T_memory)\n",
    "\n",
    "decode_eps = 0.05\n",
    "decode_den = np.maximum(decode_T_compute, decode_T_memory)\n",
    "decode_boundary = np.abs(decode_T_compute - decode_T_memory) / np.where(decode_den == 0, 1, decode_den) <= decode_eps\n",
    "di, dj = np.where(decode_boundary)\n",
    "decode_boundary_L = decode_L_vals[di]\n",
    "decode_boundary_S = decode_S_vals[dj]\n",
    "decode_boundary_Z = decode_T_compute[di, dj]\n",
    "\n",
    "make_surface(\n",
    "    decode_S_vals,\n",
    "    decode_L_vals,\n",
    "    decode_T_compute,\n",
    "    decode_boundary_S,\n",
    "    decode_boundary_L,\n",
    "    decode_boundary_Z,\n",
    "    \"Decode \u2014 T_compute(S,L) per token\",\n",
    "    \"Time per token (s)\",\n",
    ")\n",
    "\n",
    "make_surface(\n",
    "    decode_S_vals,\n",
    "    decode_L_vals,\n",
    "    decode_T_memory,\n",
    "    decode_boundary_S,\n",
    "    decode_boundary_L,\n",
    "    decode_boundary_Z,\n",
    "    \"Decode \u2014 T_memory(S,L) per token\",\n",
    "    \"Time per token (s)\",\n",
    ")\n",
    "\n",
    "make_surface(\n",
    "    decode_S_vals,\n",
    "    decode_L_vals,\n",
    "    decode_T_max,\n",
    "    decode_boundary_S,\n",
    "    decode_boundary_L,\n",
    "    decode_boundary_Z,\n",
    "    \"Decode \u2014 max(T) per token\",\n",
    "    \"Time per token (s)\",\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IHsO1RVad4bU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759487429027,
     "user_tz": -180,
     "elapsed": 143,
     "user": {
      "displayName": "ziv beker",
      "userId": "07904590467861271362"
     }
    },
    "outputId": "81036767-a28e-4c3c-b139-cd923bcb8b66"
   },
   "id": "IHsO1RVad4bU",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}